{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiarayosianti/GWR-Time/blob/main/GWR_Time_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import modules"
      ],
      "metadata": {
        "id": "4QmcbkCqL5kF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary modules"
      ],
      "metadata": {
        "id": "pGGoT-mkqQFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mgwr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from tqdm import tqdm\n",
        "from pickle import TRUE\n",
        "from mgwr.gwr import GWR\n",
        "from mgwr.sel_bw import Sel_BW\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.compat import lzip\n",
        "import statsmodels.stats.api as sms\n",
        "from scipy.stats import norm, kstest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mgwr.diagnostics import get_CV, get_AIC\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.dates as dates"
      ],
      "metadata": {
        "id": "RA8tJcK0pnG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function"
      ],
      "metadata": {
        "id": "DV5B1u7cUwYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot seasonal variabel respon\n",
        "def seasonal_plot(city):\n",
        "  fig, ax = plt.subplots(figsize=(10, 3))\n",
        "  fig.autofmt_xdate()\n",
        "  xfmt = dates.DateFormatter('%d-%m-%y')\n",
        "  ax.xaxis.set_major_formatter(xfmt)\n",
        "  df_city = data.loc[data['kota'] == city]\n",
        "  df_city = df_city.set_index('Tanggal')\n",
        "  df_city.index = pd.to_datetime(df_city.index)\n",
        "  df_city = df_city.asfreq('D')\n",
        "  sd_city = seasonal_decompose(df_city.PM10)\n",
        "  ax.plot_date(df_city.index.to_pydatetime(), sd_city.seasonal, '-')\n",
        "  start_date = mdates.datestr2num('2022-12-27')\n",
        "  end_date = mdates.datestr2num('2024-01-02')\n",
        "  ax.set_xlim(start_date, end_date)\n",
        "  ax.xaxis.set_minor_locator(dates.WeekdayLocator(byweekday=(1), interval=1))\n",
        "  ax.xaxis.set_minor_formatter(dates.DateFormatter('%d-%m-%y'))\n",
        "  plt.setp(ax.xaxis.get_minorticklabels(), rotation=90, ha=\"right\", fontsize=7)\n",
        "  ax.xaxis.grid(True, which=\"minor\")\n",
        "  ax.yaxis.grid()\n",
        "  plt.setp(ax.get_xticklabels(), visible=False)\n",
        "  plt.yticks(fontsize=7)\n",
        "  plt.title('Seasonal Component of PM$_{{10}}$ in {} City'.format(city))\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Seasonality')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Time related feature engineering with sine/cosine transformation\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "def sin_transformer(period):\n",
        "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
        "def cos_transformer(period):\n",
        "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))\n",
        "\n",
        "# Split the dataset for train, validation, and test data\n",
        "def split_data(city, dataset, train_frac, val_frac, test_frac, N_samples):\n",
        "    location_current = dataset.loc[(dataset['kota'] == city)]\n",
        "    location_current = location_current.reset_index()\n",
        "    train, val, test = location_current.loc[:int(train_frac * N_samples-1), :], location_current.loc[int(train_frac * N_samples):int((val_frac + train_frac) * N_samples-1), :], location_current.loc[int((val_frac + train_frac) * N_samples):, :]\n",
        "    return train, val, test\n",
        "\n",
        "# Breusch-Pagan Test\n",
        "def BP_test(df_train):\n",
        "  fit = smf.ols('PM10 ~ Tavg + RH_avg + ff_avg + RR + week_sin + week_cos' , data = df_train).fit()\n",
        "  # Conduct the Breusch-Pagan test\n",
        "  labels = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value'] # LM: Lagrange multiplier\n",
        "  # Get the test result\n",
        "  test_result = sms.het_breuschpagan(fit.resid, fit.model.exog)\n",
        "  if test_result[1]<0.05: result_hipotesis = 'Result: heteroscedasticity exists'\n",
        "  return result_hipotesis, lzip(labels, test_result)\n",
        "\n",
        "# Calibrate GWR model\n",
        "def calibrate_gwr(coor, df_y, df_x, kernel, fixed, bw_min=None, bw_max=None):\n",
        "  # Calibrate GWR model\n",
        "  if fixed == False:\n",
        "    # in adaptive bandwidth we are using min bandwidth and max bandwidth to prevent error\n",
        "    gwr_selector = Sel_BW(coor, df_y, df_x, kernel=kernel, fixed=fixed, spherical=True)\n",
        "    gwr_bw = gwr_selector.search(criterion=\"CV\", bw_min=bw_min, bw_max=bw_max)\n",
        "    gwr_model = GWR(coords=coor, y=df_y, X=df_x, bw=gwr_bw, kernel=kernel, fixed=fixed, spherical=True)\n",
        "    gwr_results = gwr_model.fit()\n",
        "  else:\n",
        "    gwr_selector = Sel_BW(coor, df_y, df_x, kernel=kernel, fixed=fixed, spherical=True)\n",
        "    gwr_bw = gwr_selector.search(criterion=\"CV\")\n",
        "    gwr_model = GWR(coords=coor, y=df_y, X=df_x, bw=gwr_bw, kernel=kernel, fixed=fixed, spherical=True)\n",
        "    gwr_results = gwr_model.fit()\n",
        "  # Result\n",
        "  AIC = get_AIC(gwr_results)\n",
        "  CV = get_CV(gwr_results)\n",
        "  R2 = gwr_results.R2\n",
        "  # p_vals_betas = gwr_results.spatial_variability(gwr_selector, 10)\n",
        "  # Kernel\n",
        "  kernel_used = None\n",
        "  if fixed==True: kernel_used='Fixed '+kernel\n",
        "  else: kernel_used='Adaptive '+kernel\n",
        "  print('Kernel    : ', kernel_used,\n",
        "        '\\nBandwidth : ', gwr_bw,\n",
        "        '\\nCV        : ', np.around(CV,30),\n",
        "        '\\nAIC       : ', np.around(AIC,30),\n",
        "        '\\nR2        : ', np.around(R2,30))\n",
        "  return gwr_model, gwr_results\n",
        "\n",
        "# Residual Normality Test\n",
        "def norm_kstest(resid):\n",
        "  loc, scale = norm.fit(resid.resid_response)\n",
        "  n = norm(loc=loc, scale=scale)\n",
        "  return kstest(resid.resid_response, n.cdf)\n",
        "\n",
        "# GWR Parameter\n",
        "def params_b(gwr_result):\n",
        "  params_b = pd.DataFrame(gwr_result.params, columns=['b0','b1','b2','b3','b4','b5','b6'])\n",
        "  params_b.drop_duplicates(inplace=True)\n",
        "  params_b.reset_index(drop=True, inplace=True)\n",
        "  params_b.index = ['Jakarta Pusat', 'Jakarta Utara', 'Jakarta Selatan', 'Jakarta Timur', 'Jakarta Barat']\n",
        "  return params_b\n",
        "\n",
        "# t Statistics\n",
        "def t_hitung(gwr_result):\n",
        "  t_values = pd.DataFrame(gwr_result.tvalues, columns=['b0','b1','b2','b3','b4','b5','b6'])\n",
        "  t_values.drop_duplicates(inplace=True)\n",
        "  t_values.reset_index(drop=True, inplace=True)\n",
        "  t_values.index = ['Jakarta Pusat', 'Jakarta Utara', 'Jakarta Selatan', 'Jakarta Timur', 'Jakarta Barat']\n",
        "  return t_values\n",
        "\n",
        "# Filtered t Statistics\n",
        "def t_filtered(gwr_result):\n",
        "  f_t_values = pd.DataFrame(gwr_result.filter_tvals(), columns=['b0','b1','b2','b3','b4','b5','b6'])\n",
        "  f_t_values.drop_duplicates(inplace=True)\n",
        "  f_t_values.reset_index(drop=True, inplace=True)\n",
        "  f_t_values.index = ['Jakarta Pusat', 'Jakarta Utara', 'Jakarta Selatan', 'Jakarta Timur', 'Jakarta Barat']\n",
        "  return f_t_values\n",
        "\n",
        "# Local Multicolinearity\n",
        "def local_coll(gwr_result):\n",
        "  LCC, VIF, CN, VDP = gwr_result.local_collinearity()\n",
        "  vif_bs = pd.DataFrame(VIF, columns=['X1','X2','X3','X4','X5','X6'])\n",
        "  vif_bs.drop_duplicates(inplace=True)\n",
        "  vif_bs.reset_index(drop=True, inplace=True)\n",
        "  vif_bs.index = ['Jakarta Pusat', 'Jakarta Utara', 'Jakarta Selatan', 'Jakarta Timur', 'Jakarta Barat']\n",
        "  return vif_bs\n",
        "\n",
        "# Evaluation metrics\n",
        "def evaluation_metrics(y_actual, y_predict):\n",
        "  em_summary = pd.DataFrame(columns = ['MAPE', 'MAE', 'RMSE'])\n",
        "  new_row = {\n",
        "            'MAPE': mean_absolute_percentage_error(y_actual, y_predict)*100,\n",
        "            'MAE': mean_absolute_error(y_actual, y_predict),\n",
        "            'RMSE': sqrt(mean_squared_error(y_actual, y_predict))\n",
        "          }\n",
        "  em_summary.loc[0] = new_row\n",
        "  return em_summary"
      ],
      "metadata": {
        "id": "hL8y4PNpU1jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess data"
      ],
      "metadata": {
        "id": "axESbateR1E4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Data"
      ],
      "metadata": {
        "id": "hbW05Nt-hw7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/new_df_clean_pm10_meteorologi.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "3rN26qkQgbyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the data has several columns such as Tanggal (date),\tTavg (temperature),\tRH_avg (humidity),\tff_avg (wind speed),\tRR (rainfall),\tkota,\tLatitude,\tLongitude, and\tPM10."
      ],
      "metadata": {
        "id": "Zx0EZnKSq3YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "ZrkX3fzAgh1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.kota.unique()"
      ],
      "metadata": {
        "id": "KQ3_Shfy8rDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 5 cities data used, include: Jakarta Pusat, Jakarta Utara, Jakarta Selatan, Jakarta Timur, and Jakarta Barat."
      ],
      "metadata": {
        "id": "8qIK51ZTrKFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Scaling"
      ],
      "metadata": {
        "id": "fhfeolYqGavh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see the mean and standar deviation before scaling\n",
        "data_x = data[['Tavg',\t'RH_avg',\t'ff_avg',\t'RR']]\n",
        "print(data_x.mean(axis=0))\n",
        "print(data_x.std(axis=0))\n",
        "\n",
        "data_y_pm10 = data[['PM10']]\n",
        "print(data_y_pm10.mean(axis=0))\n",
        "print(data_y_pm10.std(axis=0))"
      ],
      "metadata": {
        "id": "EKksIieLG5CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling data\n",
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "data_x_scaled_weather = scaler_x.fit_transform(data_x)\n",
        "print(\"X scaled shape :\", data_x_scaled_weather.shape)\n",
        "print(\"X variables mean :\", data_x_scaled_weather.mean(axis=0))\n",
        "print(\"X variables std :\", data_x_scaled_weather.std(axis=0))\n",
        "\n",
        "data_y_scaled_pm10 = scaler_y.fit_transform(data_y_pm10)\n",
        "print(\"Y scaled shape :\", data_y_scaled_pm10.shape)\n",
        "print(\"Y variable mean :\", data_y_scaled_pm10.mean(axis=0))\n",
        "print(\"Y variable std :\", data_y_scaled_pm10.std(axis=0))\n",
        "\n",
        "data_x_scaled = pd.DataFrame(data_x_scaled_weather, columns = ['Tavg',\t'RH_avg',\t'ff_avg',\t'RR'])\n",
        "data_y_scaled = pd.DataFrame(data_y_scaled_pm10, columns = ['PM10'])\n",
        "\n",
        "data_scaled = data[['Tanggal','kota', 'Latitude', 'Longitude']]\n",
        "data_scaled = pd.concat([data_scaled, data_y_scaled, data_x_scaled], axis=1)\n",
        "print(\"Data scaled shape :\", data_scaled.shape)\n",
        "data_scaled.head()"
      ],
      "metadata": {
        "id": "TFVq5XNdjfEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_scaled.info()"
      ],
      "metadata": {
        "id": "FZebMYN_3z6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time related feature engineering"
      ],
      "metadata": {
        "id": "fvP7-dvC4crn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = data.kota.unique()\n",
        "for city in cities:\n",
        "  seasonal_plot(city)"
      ],
      "metadata": {
        "id": "gG5pZf-DLu1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making weekly variables\n",
        "weeks = pd.DatetimeIndex(data_scaled['Tanggal']).isocalendar().week.astype(np.int64)\n",
        "week = pd.DataFrame(weeks.values,columns=[\"week\"])\n",
        "week['week_sin'] = sin_transformer(52).fit_transform(week)[\"week\"]\n",
        "week['week_cos'] = cos_transformer(52).fit_transform(week)[\"week\"]\n",
        "week.head()"
      ],
      "metadata": {
        "id": "g7sGDGoChTjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "week.week.unique()"
      ],
      "metadata": {
        "id": "mz48O4Ath8Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ready = data_scaled[['Tanggal','kota', 'Latitude', 'Longitude', 'PM10', 'Tavg',\t'RH_avg',\t'ff_avg',\t'RR']]\n",
        "data_ready = pd.concat([data_ready, week], axis=1)\n",
        "data_ready.drop(['week'], axis=1, inplace=True)\n",
        "data_ready.head()"
      ],
      "metadata": {
        "id": "iajR9tCL6hk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ready.info()"
      ],
      "metadata": {
        "id": "Imfs2SSq-XJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split the dataset"
      ],
      "metadata": {
        "id": "kb2E4MswC-KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "N_samples = 365\n",
        "train_frac = 0.6\n",
        "val_frac = 0.2\n",
        "test_frac = 0.2\n",
        "\n",
        "train_size = int(N_samples * train_frac)\n",
        "val_size = int(N_samples * val_frac)\n",
        "test_size = N_samples - train_size - val_size\n",
        "print(\"Data train rows      :\", train_size)\n",
        "print(\"Data validation rows :\", val_size)\n",
        "print(\"Data test rows       :\", test_size)\n",
        "\n",
        "df_train = pd.DataFrame()\n",
        "df_val = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "cities = data_scaled['kota'].unique()\n",
        "print(\"\\nCities :\", cities,\"\\n\")\n",
        "\n",
        "for city in tqdm(cities):\n",
        "    d_train, d_val, d_test = split_data(city, data_ready, train_frac, val_frac, test_frac, N_samples)\n",
        "    df_train = pd.concat([df_train,d_train])\n",
        "    df_val = pd.concat([df_val,d_val])\n",
        "    df_test = pd.concat([df_test,d_test])\n",
        "\n",
        "print(\"\\n \\nTrain shape :\", df_train.shape)\n",
        "print(\"Val shape :\", df_val.shape)\n",
        "print(\"Test shape :\", df_test.shape)"
      ],
      "metadata": {
        "id": "amYQ83hKZ_yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "id": "3ZRqj88mGUzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the data\n",
        "train_X = np.array(df_train[['Tavg',\t'RH_avg',\t'ff_avg',\t'RR', 'week_sin', 'week_cos']]).reshape(-1, 6)\n",
        "val_X = np.array(df_val[['Tavg',\t'RH_avg',\t'ff_avg',\t'RR', 'week_sin', 'week_cos'   ]]).reshape(-1, 6)\n",
        "test_X = np.array(df_test[['Tavg',\t'RH_avg',\t'ff_avg',\t'RR', 'week_sin', 'week_cos' ]]).reshape(-1, 6)\n",
        "\n",
        "train_y = np.array(df_train['PM10']).reshape(-1, 1)\n",
        "val_y = np.array(df_val['PM10']).reshape(-1, 1)\n",
        "test_y = np.array(df_test['PM10']).reshape(-1, 1)\n",
        "\n",
        "u_train = df_train['Longitude']\n",
        "v_train = df_train['Latitude']\n",
        "coords_train = list(zip(u_train,v_train))\n",
        "\n",
        "u_val = df_val['Longitude']\n",
        "v_val = df_val['Latitude']\n",
        "coords_val = np.array(list(zip(u_val,v_val)))\n",
        "\n",
        "u_test = df_test['Longitude']\n",
        "v_test = df_test['Latitude']\n",
        "coords_test = np.array(list(zip(u_test,v_test)))\n",
        "\n",
        "print(\"Train shape :\", train_X.shape, train_y.shape, len(coords_train))\n",
        "print(\"Val shape :\", val_X.shape, val_y.shape, len(coords_val))\n",
        "print(\"Test shape :\", test_X.shape, test_y.shape, len(coords_test))"
      ],
      "metadata": {
        "id": "sQRDF8cwzacg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "SFV5r6nyS7cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val"
      ],
      "metadata": {
        "id": "j8EejuFqTO32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "FjqnOfOlTPDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Breuch Pagan test"
      ],
      "metadata": {
        "id": "gvjotciIbinS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BP_test(df_train)"
      ],
      "metadata": {
        "id": "LtCUIi6_7Dcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model GWR"
      ],
      "metadata": {
        "id": "x9BYlhouUWzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adaptive bisquare"
      ],
      "metadata": {
        "id": "OlTa8IVvVWpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pm10_ab, result_pm10_ab = calibrate_gwr(coor = coords_train,\n",
        "                            df_y = train_y,\n",
        "                            df_x = train_X,\n",
        "                            kernel = 'bisquare',\n",
        "                            fixed = False,\n",
        "                            bw_min = 220,\n",
        "                            bw_max = 500\n",
        "                            )"
      ],
      "metadata": {
        "id": "wlakeZixIzN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fixed bisquare"
      ],
      "metadata": {
        "id": "qOek5BKWM1AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pm10_fb,result_pm10_fb = calibrate_gwr(coor = coords_train,\n",
        "                            df_y = train_y,\n",
        "                            df_x = train_X,\n",
        "                            kernel = 'bisquare',\n",
        "                            fixed = True\n",
        "                            )"
      ],
      "metadata": {
        "id": "GslIcHkmGOdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adaptive gaussian"
      ],
      "metadata": {
        "id": "7VB7VjcUrkrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pm10_gs,result_pm10_gs = calibrate_gwr(coor = coords_train,\n",
        "                            df_y = train_y,\n",
        "                            df_x = train_X,\n",
        "                            kernel = 'gaussian',\n",
        "                            fixed = False,\n",
        "                            bw_min = 220,\n",
        "                            bw_max = 500\n",
        "                            )"
      ],
      "metadata": {
        "id": "fDj3SOLVdMH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fixed gaussian"
      ],
      "metadata": {
        "id": "k3X59E7RN21z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pm10_fgs,result_pm10_fgs = calibrate_gwr(coor = coords_train,\n",
        "                            df_y = train_y,\n",
        "                            df_x = train_X,\n",
        "                            kernel = 'gaussian',\n",
        "                            fixed = True\n",
        "                            )"
      ],
      "metadata": {
        "id": "z2CS_jJndagg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adaptive exponential"
      ],
      "metadata": {
        "id": "nMWyGtabrlkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pm10_ex,result_pm10_ex = calibrate_gwr(coor = coords_train,\n",
        "                            df_y = train_y,\n",
        "                            df_x = train_X,\n",
        "                            kernel = 'exponential',\n",
        "                            fixed = False,\n",
        "                            bw_min = 220,\n",
        "                            bw_max = 500\n",
        "                            )"
      ],
      "metadata": {
        "id": "8bFrOuGpdwVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fixed exponential"
      ],
      "metadata": {
        "id": "amjYfIuaOdar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pm10_fex, result_pm10_fex = calibrate_gwr(coor = coords_train,\n",
        "                                  df_y = train_y,\n",
        "                                  df_x = train_X,\n",
        "                                  kernel = 'exponential',\n",
        "                                  fixed = True\n",
        "                                  )"
      ],
      "metadata": {
        "id": "bf5RuhCGd-N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_kstest(result_pm10_fex)"
      ],
      "metadata": {
        "id": "k6TkjNQ2oPL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_pm10_fex.summary()"
      ],
      "metadata": {
        "id": "VbmyAMMbOdas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "params_b_pm10_fex = params_b(result_pm10_fex)\n",
        "params_b_pm10_fex"
      ],
      "metadata": {
        "id": "6panc43gOdat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t Statistics\n",
        "t_hitung(result_pm10_fex)"
      ],
      "metadata": {
        "id": "5yBkPfLvOdat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t filter\n",
        "t_filtered(result_pm10_fex)"
      ],
      "metadata": {
        "id": "Sgzy2VuSOdau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t table\n",
        "result_pm10_fex.critical_tval()"
      ],
      "metadata": {
        "id": "X8qnDgB3A5O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# local multicolinearity\n",
        "local_coll(result_pm10_fex)"
      ],
      "metadata": {
        "id": "gJmByN1jfAk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics data train\n",
        "yhats_inv_pm10_train_fex = scaler_y.inverse_transform(result_pm10_fex.predy)\n",
        "train_y_inv_pm10_fex = scaler_y.inverse_transform(train_y)\n",
        "evaluation_metrics(train_y_inv_pm10_fex, yhats_inv_pm10_train_fex)"
      ],
      "metadata": {
        "id": "vAOgow71rMei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale_fex = result_pm10_fex.scale\n",
        "residuals_fex = result_pm10_fex.resid_response\n",
        "\n",
        "# predict with validation data\n",
        "results_val_fex = model_pm10_fex.predict(coords_val, val_X, scale_fex, residuals_fex)\n",
        "predicted_y_val_fex = results_val_fex.predictions\n",
        "\n",
        "# evaluation metrics data validation\n",
        "yhats_inv_pm10_val_fex = scaler_y.inverse_transform(predicted_y_val_fex)\n",
        "val_y_inv_pm10_fex = scaler_y.inverse_transform(val_y)\n",
        "evaluation_metrics(val_y_inv_pm10_fex, yhats_inv_pm10_val_fex)"
      ],
      "metadata": {
        "id": "VaE7hJEKqgm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict with test data\n",
        "results_test_fex = model_pm10_fex.predict(coords_test, test_X, scale_fex, residuals_fex)\n",
        "predicted_y_test_fex = results_test_fex.predictions\n",
        "\n",
        "# evaluation metrics data test\n",
        "yhats_inv_pm10_test_fex = scaler_y.inverse_transform(predicted_y_test_fex)\n",
        "test_y_inv_pm10_fex = scaler_y.inverse_transform(test_y)\n",
        "evaluation_metrics(test_y_inv_pm10_fex, yhats_inv_pm10_test_fex)"
      ],
      "metadata": {
        "id": "KiE2fyfjOdau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End of notebook"
      ],
      "metadata": {
        "id": "5zQJ0ROgYiIx"
      }
    }
  ]
}